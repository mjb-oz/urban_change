{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Picking Tool - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import gdal\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider, FloatSlider, Dropdown\n",
    "from IPython.display import display\n",
    "\n",
    "from skimage import exposure\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function: getData\n",
    "This code is specific to the intermediate output files from Peter's urban change algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(study_area):\n",
    "    # build a list of all files in the directory (ie the folder for that location)\n",
    "    location = study_area + '/'\n",
    "    files = os.listdir(location)\n",
    "\n",
    "    # build a list of all the NBAR*.img file names and which bands they represent\n",
    "    NBARfiles = []\n",
    "    bands = []\n",
    "    for file in files:\n",
    "        if file[-4::] == '.img' and file[0:4] == 'NBAR':\n",
    "            NBARfiles.append(file)\n",
    "            bands.append(file.split('NBAR_')[1].split('.img')[0])\n",
    "\n",
    "    # open all the .img files with NBAR in the name, convert to numpy array, swap axes so order is (x, y, t)\n",
    "    # and save to dict\n",
    "    raw_data = {}\n",
    "    for i in range(len(NBARfiles)):\n",
    "        raw_data[bands[i]] = gdal.Open(location + NBARfiles[i]).ReadAsArray().swapaxes(0,2)\n",
    "#     num_scenes = len(raw_data['red'][0][0])   # delete this?\n",
    "\n",
    "    # build a list of all the dates represented by each band in the NBAR files\n",
    "    # reuse the list of NBAR file names, but this time access the .hdr file\n",
    "    in_dates = False\n",
    "    dates = []\n",
    "    for line in open(location + NBARfiles[0].split('.img')[0] + '.hdr'):\n",
    "        if line[0] == '}':\n",
    "            continue\n",
    "        if in_dates:\n",
    "            dates.append(line.split(',')[0].strip())\n",
    "        if line[0:10] == 'band names':\n",
    "            in_dates = True\n",
    "\n",
    "    # save list of satellite originated bands\n",
    "    sat_bands = bands.copy()\n",
    "\n",
    "    # add the yet to be calculated derivative bands to the overall bands list\n",
    "    bands += ['cloud_mask']\n",
    "\n",
    "    # building the Xarray\n",
    "    # define the size for the numpy array that will hold all the data for conversion into XArray\n",
    "    x = len(raw_data['red'])\n",
    "    y = len(raw_data['red'][0])\n",
    "    t = len(raw_data['red'][0][0])\n",
    "    n = len(bands)\n",
    "\n",
    "    # create an empty numpy array of the correct size\n",
    "    alldata = np.zeros((x, y, t, n), dtype=np.float32)\n",
    "\n",
    "    # populate the numpy array with the satellite data\n",
    "    # turn all no data NBAR values to NaNs\n",
    "    for i in range(len(sat_bands)):\n",
    "        alldata[:,:,:,i] = raw_data[sat_bands[i]]\n",
    "        alldata[:,:,:,i][alldata[:,:,:,i] == -999] = np.nan\n",
    "\n",
    "    # convert the numpy array into an xarray, with appropriate lables, and axes names\n",
    "    data = xr.DataArray(alldata, coords = {'x':range(x), 'y':range(y), 'date':dates, 'band':bands},\n",
    "                 dims=['x', 'y', 'date', 'band'])\n",
    "    \n",
    "    # import cloudmask and add to xarray\n",
    "    cloudmask = gdal.Open(location + '/tsmask.img').ReadAsArray().swapaxes(0,2)\n",
    "    data.loc[:,:,:,'cloud_mask'] = cloudmask\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function: drawTrainingPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawTrainingPlot(study_area, scene_num, covertype):\n",
    "    # kept for easy extnesion to multiple subplots for the training view\n",
    "    ax1 = drawTrainingScene(study_area, scene_num, covertype)   \n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function: drawTrainingScene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawTrainingScene(study_area, scene_num, covertype):\n",
    "    # get data for selected study area\n",
    "    data = getData(study_area)\n",
    "    \n",
    "    # colour map included incase of need to display false colour or other in the future\n",
    "    # could change this to an ordereddict and remove the RGB list created below...?\n",
    "    colourmap = {'R':'red', 'G':'green', 'B':'blue'}\n",
    "    \n",
    "    # combine the data for the 3 bands to be displayed into a single numpy array\n",
    "    h = data.shape[1]\n",
    "    w = data.shape[0]\n",
    "    t = data.shape[2]\n",
    "    if scene_num > (t -1):\n",
    "        scene_num = t - 1\n",
    "    RGB = ['R','G','B']\n",
    "    date = str(data[:,:,scene_num].date.values)\n",
    "    \n",
    "    # create array to store the RGB info in, and fill by looping through the colourmap variable\n",
    "    # note the .T at the end, because the data array is setup as a (x,y,t), but imshow works (y,x)\n",
    "    rawimg = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    for i in range(len(RGB)):     \n",
    "        rawimg[:,:,i] = data[:,:,scene_num].sel(band=colourmap[RGB[i]]).T\n",
    "        \n",
    "    # equalizing for all bands together\n",
    "    # goal is to make is human interpretable\n",
    "    img_toshow = exposure.equalize_hist(rawimg, mask = np.isfinite(rawimg))    \n",
    "\n",
    "    # displaying the results and formatting the axes etc\n",
    "    plt.imshow(img_toshow)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title('True Colour Landsat Scene, taken\\n' + date + ', over ' + study_area)\n",
    "    \n",
    "    otherpicks = np.zeros((h,w), dtype=np.uint8)\n",
    "    picks = np.zeros((h,w), dtype=np.uint8)\n",
    "    if study_area in trainingdata.index:\n",
    "        if scene_num in trainingdata.loc[study_area].index:\n",
    "            temp = trainingdata.loc[study_area].loc[scene_num]\n",
    "            for i in range(len(temp)):\n",
    "                if temp.iloc[i]['landcover'] == landcover[covertype]:\n",
    "                    position = temp.iloc[i].name\n",
    "                    picks[position[0],position[1]] = 1\n",
    "                else:\n",
    "                    position = temp.iloc[i].name\n",
    "                    otherpicks[position[0],position[1]] = 1\n",
    "            allpicks = np.zeros((h,w,4), dtype = np.float32)\n",
    "            allpicks[:,:,0] = picks\n",
    "            allpicks[:,:,3][picks != 0] = 1\n",
    "            allpicks[:,:,2] = otherpicks\n",
    "            allpicks[:,:,3][otherpicks != 0] = 1\n",
    "            allpicks[allpicks == 0] = np.nan\n",
    "\n",
    "            ax.imshow(allpicks)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function: train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some broad scope variables that need setting up\n",
    "\n",
    "global xpos\n",
    "global ypos\n",
    "xpos = 0\n",
    "ypos = 0\n",
    "\n",
    "# easier to work with integers than strings, so map the planned training classes to integers\n",
    "landcover = {'vegetation':1,'urban':2,'earth':3,'water':4}\n",
    "# range of pretermined study areas to use as sources for training data\n",
    "study_areas = ['mtbarker', 'molonglo', 'nperth', 'swbris', 'swmelb', 'swsyd']\n",
    "\n",
    "# setup a multilevel heirachrical index dataframe to store the results\n",
    "# storing the training data in this format is way more memory efficient than in an Xarray of same size as data\n",
    "# but it takes a lot of processing and manipulation to get it into a more useable form\n",
    "\n",
    "trainidx = pd.MultiIndex(levels = [[]]*4, labels = [[]]*4, names=['study_area', 'scene_num', 'row','column'])\n",
    "traincols = ['landcover']\n",
    "trainingdata = pd.DataFrame(index = trainidx, columns = traincols)\n",
    "\n",
    "def train(study_area, scene_num, covertype):\n",
    "\n",
    "    def onclick(event):\n",
    "        # defining what to do on a click event\n",
    "        \n",
    "        # I don't understand why this need to be declared global again, but it breaks without these lines\n",
    "        global xpos\n",
    "        global ypos\n",
    "        # need to cast to int as result is a float, and can't index a list with a float\n",
    "        xpos = int(event.xdata)\n",
    "        ypos = int(event.ydata)\n",
    "        # save the results of the click to the training data dataframe\n",
    "        trainingdata.loc[(study_area, scene_num, ypos, xpos)] = [landcover[covertype]]\n",
    "        # redraw with the trained pixels updated on the image\n",
    "        drawTrainingPlot(study_area, scene_num, covertype)\n",
    "    \n",
    "    # control the figure size\n",
    "    fig = plt.figure(figsize=[10,10])\n",
    "    axs = fig.axes\n",
    "    plt.subplots_adjust(hspace = 0.6)\n",
    "    \n",
    "    # draw the figure\n",
    "    drawTrainingPlot(study_area, scene_num, covertype)\n",
    "    #connect the click event action to the figure\n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Training Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c00e8e62444a61bf947eaa60a7203e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description='Study Area', options=('mtbarker', 'molonglo', 'nperth', 'swbris', 'swmelb', 'swsyd'), value='mtbarker'), IntSlider(value=1, description='Scene Number', max=2000), Dropdown(description='Landcover', options=('vegetation', 'urban', 'earth', 'water'), value='vegetation'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    interact(train,\n",
    "             study_area = Dropdown(options=study_areas, value = study_areas[0], description='Study Area', disabled = False),\n",
    "             scene_num = IntSlider(value = 1, min = 0, max = 2000,description = \"Scene Number\"),\n",
    "             covertype = Dropdown(options=list(landcover.keys()), value=list(landcover.keys())[0], description='Landcover', disabled = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>landcover</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study_area</th>\n",
       "      <th>scene_num</th>\n",
       "      <th>row</th>\n",
       "      <th>column</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">mtbarker</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">38</th>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">28</th>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">131</th>\n",
       "      <th>43</th>\n",
       "      <th>116</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">40</th>\n",
       "      <th>116</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <th>119</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <th>141</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 landcover\n",
       "study_area scene_num row column           \n",
       "mtbarker   1         38  101             1\n",
       "                         105             1\n",
       "                     32  103             1\n",
       "                     29  104             1\n",
       "                     28  105             1\n",
       "                         107             1\n",
       "           131       43  116             3\n",
       "                     40  116             3\n",
       "                         118             3\n",
       "                     44  119             3\n",
       "                     120 141             3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the outputs of the training data generation process\n",
    "trainingdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Results Manipulation and Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/preprocessing/data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.39479834, -0.20103183, -0.4579601 ,  0.56202102, -0.32830667,\n",
       "        -0.41272277],\n",
       "       [-0.46247533, -0.46942592, -0.36761388,  0.22592355, -0.47991425,\n",
       "        -0.3863377 ],\n",
       "       [ 0.36207926,  0.46474674, -0.29363525,  0.55288416,  0.47928971,\n",
       "        -0.17688371],\n",
       "       [-0.10133391,  0.74710363, -0.27756268,  0.44000477,  0.39239869,\n",
       "        -0.08334096],\n",
       "       [-0.08646604,  0.63748747, -0.44228828,  0.44594139,  0.07938063,\n",
       "        -0.43052226],\n",
       "       [ 0.11182161,  0.6622445 , -0.35275033,  0.56127864,  0.29579604,\n",
       "        -0.14821024],\n",
       "       [-0.06411101,  0.10958982,  0.47482851, -0.34458989,  0.51077384,\n",
       "         0.61545563],\n",
       "       [ 0.58603477,  0.10836481,  0.46952084, -0.40408906,  0.09298779,\n",
       "         0.50242996],\n",
       "       [ 0.61855698,  0.11437855,  0.49557707, -0.39323774,  0.17063899,\n",
       "         0.41827586],\n",
       "       [ 0.33802253,  0.1401719 ,  0.60733396, -0.35957476,  0.47563392,\n",
       "         0.37645262],\n",
       "       [-0.29709566, -0.61186749, -0.10932432, -0.43597624, -0.51418245,\n",
       "        -0.2663486 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aim is to get the data from the dataframe (which holds references to the pixel's location, along with the\n",
    "# assigned class for that pixel), use it to extract the spectral data for that pixel, format it appropriately\n",
    "# and pass it to the classification algorithm to teach it.\n",
    "\n",
    "# empty lists where the spectral data for each pixel (X) and the landcover class (Y) will be stored\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# useful variable for pulling out only the spectral data\n",
    "sat_bands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2']\n",
    "dc_bands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'cloud_mask']\n",
    "\n",
    "# loop through the different locations used for the training data.\n",
    "for loc in trainingdata.index.levels[0]:\n",
    "    \n",
    "    # build the Xarray for that location\n",
    "    data = getData(loc)\n",
    "    # only look at the training data for that location\n",
    "    subset = trainingdata.loc[loc]\n",
    "    # for each row (ie each pick) at that location\n",
    "    for i in range(len(subset)):\n",
    "        # unpack the multilevel pandas index into components for accessing the correct Xarray pixel\n",
    "        scene, y, x = subset.iloc[i].name\n",
    "        if data[x, y, scene].sel(band='cloud_mask').values == 0:\n",
    "            # if the pixel is valid (no cloud), take the spectral bands\n",
    "            X_vect = data[x, y, scene].sel(band=sat_bands).values\n",
    "            if np.isfinite(X_vect).all():\n",
    "                # if all the bands have readings (no NaNs), save the relevant bits into X and Y\n",
    "                Y.append(subset.iloc[i].values[0])        \n",
    "                X.append(np.reshape(X_vect,(len(X_vect),1)).T)\n",
    "\n",
    "# join the list of spectral vectors into a single 2D array\n",
    "X = np.concatenate(X, axis = 0)\n",
    "        \n",
    "from sklearn import preprocessing\n",
    "\n",
    "# scale and normalize the data\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_normalized = preprocessing.normalize(X_scaled)\n",
    "X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# create a support vector classifer, and fit the data to it\n",
    "clf = svm.SVC()\n",
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting Remaining Data for Classification & Classifying It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run the classification over mt barker, will need to loop this through all eventually\n",
    "data = getData('mtbarker')\n",
    "\n",
    "#setting up the xarray to store the results for easy plotting later\n",
    "for newband in ['landcover','predicted_landcover']:\n",
    "    test = data[:,:,:].sel(band='red').copy()\n",
    "    test.band.values = newband\n",
    "    test.values[:] = np.nan\n",
    "    data = xr.concat([data, test], dim='band')\n",
    "\n",
    "shape = data.values.shape\n",
    "\n",
    "# classify one scene at a time, save the results to the xarray    \n",
    "for scene in range(1,2):\n",
    "    \n",
    "    # setting up dataframe multilevel indexes\n",
    "    col_idx = list(range(shape[0])) * shape[1]\n",
    "    row_idx = []\n",
    "    study_area = 'mtbarker'\n",
    "    for i in range(shape[1]):\n",
    "        row_idx += [i] * shape[0]\n",
    "    scene_idx = [scene] * (shape[0] * shape[1])\n",
    "\n",
    "    # reshape the data into a 2D flat array for scikit learn\n",
    "    flattened = data[:,:,scene].sel(band=dc_bands).values.reshape(shape[0] * shape[1], len(dc_bands))\n",
    "\n",
    "    # add the data to a new DataFrame, set up the columns and index\n",
    "    alldata = pd.DataFrame(flattened)\n",
    "    alldata.columns = dc_bands\n",
    "    alldata['row'] = row_idx\n",
    "    alldata['column'] = col_idx\n",
    "    alldata['scene_num'] = scene_idx\n",
    "    alldata['study_area'] = study_area\n",
    "    alldata = alldata.set_index(['study_area','scene_num','row','column'])\n",
    "\n",
    "    # join in the training data. This is a SQL left join, so only adds data to current study area\n",
    "    alldata = alldata.reset_index().join(trainingdata[['landcover']], on=trainingdata.index.names).set_index(alldata.index.names)\n",
    "\n",
    "    # reduce all data down to valid pixels (ie cloudmask), and non-training pixels (ie landcover is still NaN)\n",
    "    datatoclassify = alldata[alldata['cloud_mask'] == 0 & np.isnan(alldata['landcover'])].copy()\n",
    "    # remove pixels with a np.nan as scikit-learn doesn't like them. Only keep spectral bands\n",
    "    datatoclassify = datatoclassify[np.isnan(datatoclassify['landcover'])][sat_bands]\n",
    "    # cast these relevant columns into a numpy array\n",
    "    datatoclassify_np = np.array(datatoclassify)\n",
    "\n",
    "    # results of predict() are a 1 dimensional numpy array of the same length as the input data\n",
    "    # assign these results to a new column in the dataframe\n",
    "    datatoclassify['predicted_landcover'] = clf.predict(datatoclassify_np)\n",
    "    \n",
    "    # SQL left join the results back onto the original data\n",
    "    alldata = alldata.reset_index().join(datatoclassify[['predicted_landcover']], on=trainingdata.index.names).set_index(alldata.index.names)\n",
    "    \n",
    "    data[:,:,scene].loc[dict(band='landcover')] = alldata['landcover'].values.reshape(shape[0],shape[1])\n",
    "    data[:,:,scene].loc[dict(band='predicted_landcover')] = alldata['predicted_landcover'].values.reshape(shape[0],shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawClassifedScene(data, scene_num, alpha):\n",
    "    \n",
    "    # colour map included incase of need to display false colour or other in the future\n",
    "    # could change this to an ordereddict and remove the RGB list created below...?\n",
    "    colourmap = {'R':'red', 'G':'green', 'B':'blue'}\n",
    "    \n",
    "    # combine the data for the 3 bands to be displayed into a single numpy array\n",
    "    h = data.shape[1]\n",
    "    w = data.shape[0]\n",
    "    t = data.shape[2]\n",
    "    \n",
    "    if scene_num > (t -1):\n",
    "        scene_num = t - 1\n",
    "    RGB = ['R','G','B']\n",
    "    date = str(data[:,:,scene_num].date.values)\n",
    "    \n",
    "    # create array to store the RGB info in, and fill by looping through the colourmap variable\n",
    "    # note the .T at the end, because the data array is setup as a (x,y,t), but imshow works (y,x)\n",
    "    rawimg = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    for i in range(len(RGB)):     \n",
    "        rawimg[:,:,i] = data[:,:,scene_num].sel(band=colourmap[RGB[i]]).T\n",
    "        \n",
    "    # equalizing for all bands together\n",
    "    # goal is to make is human interpretable\n",
    "    img_toshow = exposure.equalize_hist(rawimg, mask = np.isfinite(rawimg))    \n",
    "\n",
    "    # displaying the results and formatting the axes etc\n",
    "    plt.imshow(img_toshow)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title('True Colour Landsat Scene, taken\\n' + date + ', over ' + study_area)\n",
    "        \n",
    "    ax.imshow(data[:,:,scene_num].sel(band='predicted_landcover'), alpha = alpha)\n",
    "    ax.imshow(data[:,:,scene_num].sel(band='landcover'), alpha = 1)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawClassifedPlots(data, scene_num, alpha):\n",
    "    # make them plot sideways\n",
    "    ax1 = drawClassifedScene(data, scene_num, alpha)\n",
    "#     ax2 = drawClassifedScene(data, scene_num, alpha = 1)\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(data, scene_num, alpha):\n",
    " \n",
    "    # control the figure size\n",
    "    fig = plt.figure(figsize=[10,10])\n",
    "    axs = fig.axes\n",
    "    plt.subplots_adjust(hspace = 0.6)\n",
    "    \n",
    "    # draw the figure\n",
    "    drawClassifedPlots(data, scene_num, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cef5c28e6c04060b2f0d07d369e8db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Scene Number', max=2000), FloatSlider(value=0.6, description='Classification Transparency', max=1.0), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    interact(check,\n",
    "             data = fixed(data),\n",
    "             scene_num = IntSlider(value = 1, min = 0, max = 2000,description = \"Scene Number\"),\n",
    "             alpha= FloatSlider(value = 0.6, min = 0, max = 1, description = \"Classification Transparency\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "818px",
    "left": "0px",
    "right": "1044px",
    "top": "111px",
    "width": "252px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "state": {
    "c52feb267d464c0681dc5b8825029c6a": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
