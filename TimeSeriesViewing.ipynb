{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Time Series Analysis Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This notebook exists to allow time series analysis of pixels or areas.\n",
    "\n",
    "This notebook has been setup to work with table of contents and heading collapsing extensions. These are definitely worth using!\n",
    "\n",
    "The output is an interactive matplotlib figure with two scenes from the area of interest rendered in true colour, along with scatter plots for the two main bands of interest for each scene, and an average spectral signature for each scene.\n",
    "\n",
    "The main benefit to this visualistion though is the ability to see the the time series trend for a band or number of bands for a given pixel or area. This is one in a single chart, which also indicates the relative location of each of the scenes being viewed on the timeseries, and also shows some key threshold lines.\n",
    "\n",
    "This particular notebook has been written to look at output from Peter's urban change detection algorithm, however, it is hoped that it should easily by ported to others' anaylsis problems with only minor tweaks, as long as the Xarray is setup the same, all that should be required is to:\n",
    "<ul><li> exclude the code that displays the urban change algorithm outputs\n",
    "<li> exclude the problem specific code (such as thresholds and change date range) on the TS analysis plot</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import gdal\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider, FloatSlider\n",
    "from IPython.display import display\n",
    "\n",
    "from skimage import exposure\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup\n",
    "\n",
    "The goal is to get the data into an Xarray. The graphing code is written to work with an Xarray with the coordinates/dimensions (X, Y, time, bands)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Importing the data\n",
    "This code is specific to the intermediate output files from Peter's urban change algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# build a list of all files in the directory (ie the folder for that location)\n",
    "location = 'mtbarker/'\n",
    "files = os.listdir(location)\n",
    "\n",
    "# build a list of all the NBAR*.img file names and which bands they represent\n",
    "NBARfiles = []\n",
    "bands = []\n",
    "for file in files:\n",
    "    if file[-4::] == '.img' and file[0:4] == 'NBAR':\n",
    "        NBARfiles.append(file)\n",
    "        bands.append(file.split('NBAR_')[1].split('.img')[0])\n",
    "\n",
    "# open all the .img files with NBAR in the name, convert to numpy array, swap axes so order is (x, y, t)\n",
    "# and save to dict\n",
    "raw_data = {}\n",
    "for i in range(len(NBARfiles)):\n",
    "    raw_data[bands[i]] = gdal.Open(location + NBARfiles[i]).ReadAsArray().swapaxes(0,2)\n",
    "num_scenes = len(raw_data['red'][0][0])\n",
    "\n",
    "# build a list of all the dates represented by each band in the NBAR files\n",
    "# reuse the list of NBAR file names, but this time access the .hdr file\n",
    "in_dates = False\n",
    "dates = []\n",
    "for line in open(location + NBARfiles[0].split('.img')[0] + '.hdr'):\n",
    "    if line[0] == '}':\n",
    "        continue\n",
    "    if in_dates:\n",
    "        dates.append(line.split(',')[0].strip())\n",
    "    if line[0:10] == 'band names':\n",
    "        in_dates = True\n",
    "\n",
    "# save list of satellite originated bands\n",
    "sat_bands = bands.copy()\n",
    "\n",
    "# add the yet to be calculated derivative bands to the overall bands list\n",
    "bands += ['evi', 'ndvi', 'albedo', 'cloud_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Building the Xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define the size for the numpy array that will hold all the data for conversion into XArray\n",
    "x = len(raw_data['red'])\n",
    "y = len(raw_data['red'][0])\n",
    "t = len(raw_data['red'][0][0])\n",
    "n = len(bands)\n",
    "\n",
    "# create an empty numpy array of the correct size\n",
    "alldata = np.zeros((x, y, t, n), dtype=np.float32)\n",
    "\n",
    "# populate the numpy array with the satellite data\n",
    "# turn all no data NBAR values to NaNs\n",
    "for i in range(len(sat_bands)):\n",
    "    alldata[:,:,:,i] = raw_data[sat_bands[i]]\n",
    "    alldata[:,:,:,i][alldata[:,:,:,i] == -999] = np.nan\n",
    "    \n",
    "# convert the numpy array into an xarray, with appropriate lables, and axes names\n",
    "data = xr.DataArray(alldata, coords = {'x':range(x), 'y':range(y), 'date':dates, 'band':bands},\n",
    "             dims=['x', 'y', 'date', 'band'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Opening the results from the urban change algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# open the results of the change algorithm, and format for eay plotting\n",
    "change = gdal.Open(location + 'change_time.img').ReadAsArray()\n",
    "\n",
    "# remove the dates, so you have a mask for change or no change\n",
    "change_flat_mask = change.copy()\n",
    "change_flat_mask[change_flat_mask != 0] = 1\n",
    "change_flat_mask[change_flat_mask == 0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Creating the calculated \"bands\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171016/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in greater\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# calculate NDVI \"band\"\n",
    "a = (data.loc[:,:,:,'nir'] - data.loc[:,:,:,'red'])\n",
    "b = (data.loc[:,:,:,'nir'] + data.loc[:,:,:,'red'])\n",
    "b_pos = b.where(b.values > 0)\n",
    "data.loc[:,:,:,'ndvi'] = np.nan\n",
    "data.loc[:,:,:,'ndvi'] = a/b_pos\n",
    "\n",
    "# calculate EVI \"band\"\n",
    "g  = 2.5\n",
    "c1 = 6\n",
    "c2 = 7.5\n",
    "l  = 1\n",
    "data.loc[:,:,:,'evi'] = g * ((a/10000) /\n",
    "    ((data.loc[:,:,:,'nir']/10000) + (c1 * (data.loc[:,:,:,'red']/10000)) - (c2 * (data.loc[:,:,:,'blue']/10000)) + l))\n",
    "\n",
    "# calculate average albedo \"band\"\n",
    "for band in sat_bands:\n",
    "    data.loc[:,:,:,'albedo'] += data.loc[:,:,:,band]\n",
    "data.loc[:,:,:,'albedo'] = data.loc[:,:,:,'albedo'] / (6 * 1000)\n",
    "\n",
    "# import cloudmask and add to xarray\n",
    "cloudmask = gdal.Open(location + '/tsmask.img').ReadAsArray().swapaxes(0,2)\n",
    "data.loc[:,:,:,'cloud_mask'] = cloudmask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Manipulation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getTimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(xpos, ypos, ts_bands, apply_cloud_mask = True):\n",
    "    \"\"\"\n",
    "    This function retrives the time series data for a given pixel and band.\n",
    "    It then applies the cloud/shadow mask (if requested) to the results and to the dates for each scene.\n",
    "    Finally, it returns the good pixels for each of the requested bands as a multi column pandas dataframe,\n",
    "    with the date formatted as a datetime object and set as in the index\n",
    "    \n",
    "    Possible flaw with logic by only masking pixels when they are clouded, not entire query area if any or some\n",
    "    is partially clouded. Need to explore this thought further\n",
    "    \"\"\"       \n",
    "    if isinstance(xpos, list) and len(xpos) == 1:\n",
    "        xpos.append(xpos[0] + 1)\n",
    "    elif not isinstance(xpos, list) and is_number(xpos):\n",
    "        xpos = [int(xpos), xpos + 1]\n",
    "        \n",
    "    if isinstance(ypos, list) and len(ypos) == 1:\n",
    "        ypos.append(ypos[0] + 1)\n",
    "    elif not isinstance(ypos, list) and is_number(ypos):\n",
    "        ypos = [int(ypos), ypos + 1]\n",
    "    \n",
    "    # if looking for an area and not masking for cloud, do this\n",
    "    if not apply_cloud_mask:\n",
    "        ts_data = pd.DataFrame(data[xpos[0]:xpos[1], ypos[0]:ypos[1],:].sel(band = ts_bands).mean(dim=['x','y'], skipna = True).to_pandas())\n",
    "        \n",
    "    # if looking for an area and masking for cloud, do this\n",
    "    else:\n",
    "        ts_data = pd.DataFrame(data[xpos[0]:xpos[1], ypos[0]:ypos[1], :].sel(band = ts_bands).where(\n",
    "            data[xpos[0]:xpos[1], ypos[0]:ypos[1], :].sel(band ='cloud_mask') == 0).mean(dim=['x','y'], skipna = True).to_pandas())\n",
    "    \n",
    "    ts_data.index = pd.to_datetime(ts_data.index) \n",
    "    ts_data.columns = [ts_bands]\n",
    "    return ts_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filterNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterNoise(df):\n",
    "    \"\"\"\n",
    "    This function applies a scipy.signal.lfilter IIR filter to the time series data to smooth out\n",
    "    some of the spikes that are visible in this timeseries for each of the columns in the supplied\n",
    "    pandas dataframe.\n",
    "    Peters C++ code used a different filter, so this function may be replaced or deprecated in the\n",
    "    future\n",
    "    \"\"\"\n",
    "    # set up required parameters for the function\n",
    "    n = 15                 # bigger n means more smoothing\n",
    "    b = [1.0 / n] * n\n",
    "    a = 1      \n",
    "    for col in df.columns:\n",
    "        df[col] = lfilter(b, a, df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcRollingAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcRollingAvg(df, window = '365D', min_periods = 6):\n",
    "    \"\"\"\n",
    "    The function uses the pandas rolling average function to calculate the yearly rolling\n",
    "    average of the bands. It returns the dataframe it was given with the column values modified\n",
    "    by the rolling average function.\n",
    "    The window size and minimum number of periods for the average to be considered valid are optional\n",
    "    parameters\n",
    "    Peter's code used either 1 or 2 years windows depending on frequency of valid observations - this might\n",
    "    be included in the future\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].rolling(window = window, min_periods = min_periods).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcYearDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcYearDiff(df, years = 1):\n",
    "    \"\"\"\n",
    "    Returns the difference between a timeseries and the timeseries at some point in the future.\n",
    "    It does this by joining a time adjusted series onto the original data and interpolating any missing\n",
    "    dates, and then cleaning up the NaN mess resulting.\n",
    "    \"\"\"\n",
    "    # convert years to days\n",
    "    days = years * 365\n",
    "    \n",
    "    # duplicate data\n",
    "    df2 = df.copy()\n",
    "\n",
    "    # reduce the index by a year, essentially moving the average for the following year back one\n",
    "    # this might need a bit of tweaking to deal with leap years...?\n",
    "    df2.index = np.array(df2.index) - np.timedelta64(days, 'D')\n",
    "    \n",
    "    # building lists of column names that will be needed\n",
    "    cols = list(df.columns)\n",
    "    newcols = []\n",
    "    interpcols = []\n",
    "    diffcols = []\n",
    "    for col in cols:\n",
    "        newcols.append(col + '-1y')\n",
    "        interpcols.append(col + '-1y_interp')\n",
    "        diffcols.append(col + '_diff')\n",
    "    \n",
    "    # rename df2 columns to avoid clashes in the merge\n",
    "    df2.columns = newcols\n",
    "\n",
    "    # SQL style outer join (ie all data is kept, NaNs for blank values)\n",
    "    df = pd.merge(df, df2, left_index=True, right_index=True, how='outer')\n",
    " \n",
    "    # interpolate the timeseries values in the future and calculate the difference from that date\n",
    "    for i in range(len(cols)):\n",
    "        df[interpcols[i]] = df[newcols[i]].interpolate(method='time')\n",
    "        df[diffcols[i]] = df[interpcols[i]] - df[cols[i]]\n",
    "\n",
    "    # tidying up unwanted rows and columns\n",
    "    # can do dropna because if there was no original data, the difference calc result is NaN\n",
    "    df = df.dropna(subset=[diffcols])\n",
    "    df = df.drop(cols + newcols + interpcols, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gatherAndPrepTSData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatherAndPrepTSData(xpos,ypos,ts_bands):\n",
    "    \"\"\"\n",
    "    This function takes the x and y coordinates of interest, along with the ts_bands dict.\n",
    "    It pulls the required data from the xarray, and applies the various processing steps specified in the dict\n",
    "    It returns a pandas dataframe of all the processed data, with a date index, and each column named as\n",
    "    specified in the dict.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    cols = []\n",
    "    # ts_bands is the very important dict, it specifies the name of the result, the band the result is built\n",
    "    # off, and which of the processing steps will be performed on that band data\n",
    "    for TS in ts_bands:\n",
    "        df = getTimeSeries(xpos, ypos, TS['band'], apply_cloud_mask = TS['cloud_mask'])\n",
    "        # drop rows with clouds masked\n",
    "        df = df.dropna(axis = 0, how = 'all')\n",
    "\n",
    "        # filter noise\n",
    "        if TS['smoothed']:\n",
    "            df = filterNoise(df)\n",
    "\n",
    "        # calculate rolling average\n",
    "        if TS['RollingAve']:\n",
    "            df = calcRollingAvg(df)\n",
    "            # drop rows with no rolling average values\n",
    "            df = df.dropna(axis = 0, how = 'all')\n",
    "\n",
    "        # calculate difference between TS value and a period into the future\n",
    "        if TS['TSDiff']:\n",
    "            df = calcYearDiff(df)\n",
    "        \n",
    "        dfs.append(df)\n",
    "        cols.append(TS['name'])\n",
    "    dfs = pd.concat(dfs, axis = 1)\n",
    "    dfs.columns = cols\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for plotting and other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define_TS_YAxisRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_TS_YAxisRange(data, DiffTS = False, n_stddevs = 0.5):\n",
    "    \"\"\"\n",
    "    This function defines the y axis range for a timeseries plot of a given band (supplied as a pandas \n",
    "    single column dataframe or series, aka data. It calculates the standard deviation of the data, and \n",
    "    returns a list with the lowest and highest values for the axes based on the number of standard deviations\n",
    "    away from the mean (which can be varied through the second parameter as desired)\n",
    "    \"\"\"\n",
    "    if DiffTS:\n",
    "        mag = data.std(skipna = True) * n_stddevs\n",
    "        return [-mag, mag]\n",
    "    else:\n",
    "        mean = data.mean(skipna = True)\n",
    "        std = data.std(skipna = True)\n",
    "        low = mean - (n_stddevs * std)\n",
    "        hi = mean + (n_stddevs * std)\n",
    "        return [low,hi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    \"\"\"\n",
    "    A quick helper function pinched from stack overflow to test if a variable is a float or int\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getSceneFilteredIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSceneFilteredIndex(scene_num, df):\n",
    "    \"\"\"\n",
    "    This function find the X axis location needed for a given scene to be displayed on the Time Series View.\n",
    "    This is used draw the lines on the timeseries that represent the scenes being viewed.\n",
    "    If the scene being viewed is part of that pixel's timeseries, the line returned is a solid line.\n",
    "    If the scene being viewed is not part of that pixel's timeseries (due to cloud masking), the\n",
    "    line returned is a dashed line.\n",
    "    The line is returned as a number, linestyle pair, for plugging into the matplotlib.axvline function\n",
    "    \"\"\"\n",
    "    # find the date of the scene_number from the list of all dates before clouds mask application\n",
    "    linedate = pd.to_datetime(dates[scene_num])\n",
    "    \n",
    "    # for the simple case, when the scene is part of the pixel's time series\n",
    "    if linedate in df.index:\n",
    "        nearest_num = df.index.get_loc(linedate)\n",
    "        return [nearest_num, '-']\n",
    "    \n",
    "    # when the pixel is not part of the time series and is more recent than the most recent valid\n",
    "    # scene, use the last valid scenes index\n",
    "    elif linedate > df.index[-1]:\n",
    "        nearest_num = df.index.get_loc(df.index[-1])\n",
    "        return [nearest_num, '--']\n",
    "    \n",
    "    # when the schene is not part of the pixel's time series, draw the line at the first valid scene's\n",
    "    # index AFTER the scene in question\n",
    "    else:   \n",
    "        nearest_num = df.index.get_loc(df[df.index > linedate].index[0])\n",
    "        return [nearest_num, '--']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getChangePeriodTimeRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChangePeriodTimeRange(df, daterange):\n",
    "    \"\"\"\n",
    "    This function changes the calculated change date from Peter's algorithm and converts it\n",
    "    to the equivalent range of row numbers for the given timeseries (supplied as a pandas dataframe).\n",
    "    The change date calculated is converted to the start and end dates of the quarter, and this is \n",
    "    turned into a datetime object, and used in boolean masking to define the first and last row\n",
    "    of that interval\n",
    "    \"\"\"\n",
    "    # flaw with the logic here, if someone passes a daterange with more than 2 entries, only the first\n",
    "    # and last are used. So it works, as long as its used well.\n",
    "    for i in range(len(daterange)):\n",
    "        year = str(int(daterange[i]))    \n",
    "        # generate the string equivalents of the start and end dates for the quarter\n",
    "        if daterange[i] % 1 == 0.125:\n",
    "            start = '-01-01'\n",
    "            end = '-03-31'\n",
    "        if daterange[i] % 1 == 0.375:\n",
    "            start = '-04-01'\n",
    "            end = '-06-30'\n",
    "        if daterange[i] % 1 == 0.625:\n",
    "            start = '-07-01'\n",
    "            end = '-09-30'\n",
    "        if daterange[i] % 1 == 0.875:\n",
    "            start = '-10-01'\n",
    "            end = '-12-31'\n",
    "        if i == 0:\n",
    "            startdate = pd.to_datetime(year + start) # turn strings into datetime objects\n",
    "        else:\n",
    "            enddate = pd.to_datetime(year + end)    \n",
    "    \n",
    "    # calculdate the start and end date index of the range bounded by start and end datetimes\n",
    "    start_idx = df[(df.index >= startdate) & (df.index <= enddate)].index[0]\n",
    "    end_idx = df[(df.index >= startdate) & (df.index <= enddate)].index[-1]    \n",
    "  \n",
    "    # get the row number of the start and end indexes\n",
    "    start_row = df.index.get_loc(start_idx)    \n",
    "    end_row = df.index.get_loc(end_idx)\n",
    "    \n",
    "    # return result as a list, ready to directly be passed to axis.set_ylim()\n",
    "    return [start_row, end_row]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getChangeDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChangeDate(xpos, ypos):\n",
    "    \"\"\"\n",
    "    This function returns the max and min change date for a given range of pixels based on the\n",
    "    output of the algorithm. It works if the range is only a single pixel.\n",
    "    It returns a string if there was no change detected in that area.\n",
    "    \"\"\"\n",
    "    # select the pixels in the area of interest\n",
    "    pix = change[ypos[0]:ypos[1], xpos[0]:xpos[1]]\n",
    "    # mask for > 0\n",
    "    pix = pix[pix > 0]\n",
    "    # if there are no pixels > 0, break things\n",
    "    if len(pix) == 0:\n",
    "        return \"No Change\"\n",
    "    # find hte max and min and return them as a list\n",
    "    mini = pix.min()\n",
    "    maxi = pix.max()\n",
    "    return [mini, maxi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drawScene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawScene(scene_num, change_trans, xpos, ypos):\n",
    "    \"\"\"\n",
    "    This function draws a landsat scene from the data in true colour, and overlays the results of the\n",
    "    change detection algorithm. The scene to be displayed is determined by the scene_num parameter, while the\n",
    "    transparency (alpha) of the change results is dictacted by the change_trans parameter (0 = transparent,\n",
    "    1 = totally opaque). It formats the axes appropriately and returns the axes to the caller.\n",
    "    It also displays the bounding box of the pixels being analysed.\n",
    "    \"\"\"\n",
    "    # colour map included incase of need to display false colour or other in the future\n",
    "    # could change this to an ordereddict and remove the RGB list created below...?\n",
    "    colourmap = {'R':'red', 'G':'green', 'B':'blue'}\n",
    "    \n",
    "    # define the current colour map to display the change results raster properly\n",
    "    current_cmap = matplotlib.cm.get_cmap('Reds_r')\n",
    "    current_cmap.set_under('k', alpha=0.0)\n",
    "    current_cmap.set_over('r', alpha=1.0)\n",
    "    current_cmap.set_bad('k', alpha=0.0)  \n",
    "    \n",
    "    # combine the data for the 3 bands to be displayed into a single numpy array\n",
    "    h = data.shape[1]\n",
    "    w = data.shape[0]\n",
    "    RGB = ['R','G','B']\n",
    "    \n",
    "    # create array to store the RGB info in, and fill by looping through the colourmap variable\n",
    "    # note the .T at the end, because the data array is setup as a (x,y,t), but imshow works (y,x)\n",
    "    rawimg = np.zeros((h, w, 3), dtype=np.float32)\n",
    "    for i in range(len(RGB)):     \n",
    "        rawimg[:,:,i] = data[:,:,scene_num].sel(band=colourmap[RGB[i]]).T\n",
    "        \n",
    "    # equalizing for all bands together\n",
    "    # goal is to make is human interpretable\n",
    "    img_toshow = exposure.equalize_hist(rawimg, mask = np.isfinite(rawimg))    \n",
    "\n",
    "    # displaying the results and formatting the axes etc\n",
    "    plt.imshow(img_toshow)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title('True Colour Landsat Scene, taken\\n' + dates[scene_num] + ', over ' + location)\n",
    "    ax.imshow(change_flat_mask, alpha = change_trans, interpolation='none', cmap = current_cmap, clim = [0.5, 0.6])\n",
    "    \n",
    "    # plot up the displayed pixel, or draw a box around the queried pixels\n",
    "    # logic re . vs box could be improved here\n",
    "    height = abs(ypos[1] - ypos[0])\n",
    "    width = abs(xpos[1] - xpos[0])\n",
    "    if height > 2 and width > 2:\n",
    "        rect = matplotlib.patches.Rectangle((xpos[0],ypos[0]), abs(xpos[1] - xpos[0]), abs(ypos[1] - ypos[0]),\n",
    "                                            color = 'blue', linestyle = '-', fill = False, alpha = change_trans)\n",
    "        ax.add_patch(rect)\n",
    "    else:\n",
    "        ax.plot((xpos[0] + xpos[1])/2, (ypos[0] + ypos[1])/2, color = 'b', marker = '.', alpha = change_trans)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drawSpectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawSpectrum(xpos, ypos, scene_num):\n",
    "    \"\"\"\n",
    "    This function draws the spectral signature for a selected range of pixels in a selected scene.\n",
    "    It gathers the data together, averages the band values, and returns them plotted on nicely labelled\n",
    "    axes, which are returned to the caller\n",
    "    \"\"\"\n",
    "    # include Landsat-8 bands incase of future work\n",
    "    bandorder = {'ultrablue':1, 'blue':2, 'green':3, 'red':4, 'nir':5, 'cirrus':6, 'swir1':7,\n",
    "                 'swir2':8, 'thermal':9,'panchromatic':10}\n",
    "    \n",
    "    # do lots of funkiness to pull the data together and order it so the data are displayed\n",
    "    # in order of increase wavelength\n",
    "    xvals = []\n",
    "    yvals = []\n",
    "    for band in sat_bands:\n",
    "        xvals.append(bandorder[band])\n",
    "        yvals.append(float(data[xpos[0]:xpos[1],ypos[0]:ypos[1],scene_num].sel(band=band).mean(dim=['x','y']).values))\n",
    "    yvals_sorted = [y for x, y in sorted(zip(xvals,yvals))]\n",
    "    xlabels_sorted = [y for x, y in sorted(zip(xvals, sat_bands))]\n",
    "    xvals_sorted = range(len(yvals))\n",
    "    \n",
    "    # plot the data, and make it look nice\n",
    "    plt.plot(xvals_sorted, yvals_sorted)\n",
    "    ax = plt.gca()\n",
    "    ax.set_title('Band Values for Selected Area')\n",
    "    ax.set_ylim([0,6000])\n",
    "    ax.set_ylabel('Average NBAR Value')\n",
    "    ax.set_xticks(xvals_sorted)\n",
    "    ax.set_xticklabels(xlabels_sorted)\n",
    "    ax.set_xlabel('Band')\n",
    "    return ax  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drawScatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawScatter(scene_num, ts_bands, xpos, ypos):\n",
    "    \"\"\"\n",
    "    This function draws a 2D scatter plot of the scene, based on the two bands of interest (specified by\n",
    "    x_axis and y_axis). It returns the scatter plot to the caller.\n",
    "    This basically assumes that the first and second bands in ts_bands are the two of most interest to the\n",
    "    user, so ts_bands needs to be structured appropriately.\n",
    "    The longer term goal would be to have dropdown boxes that would allow the user to select which band from the\n",
    "    xarray they would like for each axis.\n",
    "    \"\"\"\n",
    "    # set the axis bands\n",
    "    x_axis = ts_bands[0]['band']\n",
    "    y_axis = ts_bands[1]['band']\n",
    "    \n",
    "    # get the 1D array of the values for each axis\n",
    "    x = data[:,:,scene_num].sel(band = x_axis).values\n",
    "    y = data[:,:,scene_num].sel(band = y_axis).values\n",
    "    \n",
    "    # pull out the values from the bounding box selected\n",
    "    sel_x = data[xpos[0]:xpos[1], ypos[0]:ypos[1], scene_num].sel(band = x_axis).values\n",
    "    #create a full size array full of NaN\n",
    "    sel_x_all = np.full(x.shape, np.nan)\n",
    "    #set the corresponding area of the NaN array to the values from the bounding box\n",
    "    sel_x_all[xpos[0]:xpos[1],ypos[0]:ypos[1]] = sel_x\n",
    "    \n",
    "    # repeat\n",
    "    sel_y = data[xpos[0]:xpos[1], ypos[0]:ypos[1], scene_num].sel(band = y_axis).values\n",
    "    sel_y_all = np.zeros_like(y)\n",
    "    sel_y_all[xpos[0]:xpos[1],ypos[0]:ypos[1]] = sel_y\n",
    "    \n",
    "    \n",
    "    # build a mask of where the values are both valid (ie not NaN)\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    mask2 = np.isfinite(sel_x_all) * np.isfinite(sel_y_all)\n",
    "    \n",
    "    # make plot, label axes and return\n",
    "    plt.plot(x[mask], y[mask],'.', color = 'blue', label = 'All Points')\n",
    "    plt.plot(sel_x_all[mask2], sel_y_all[mask2],'.', color = 'red', label = 'Selected Points')\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel(x_axis)\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylabel(y_axis)\n",
    "    ax.set_ylim([0,5])\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drawTimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawTimeSeries(xpos,ypos,ts_bands,left_scene_num = 0, right_scene_num = data.shape[2]-1):\n",
    "    \"\"\"\n",
    "    This function draws the time series for a given pixel and band (or list of 2 bands).\n",
    "    It calls the timeSeries function to gather the data and strip out the cloud, and then\n",
    "    formats the axes appropriately for up to 2 bands and returns them to the caller.\n",
    "    It also indicates where on the time axes each of the scenes being viewed sits, and displays them as\n",
    "    either solid or dashed lines depending on if the pixels in question are cloud masked or not.\n",
    "    It also displays as a yellow box the time range over which the change detection algorithm has indicated\n",
    "    change has occured.\n",
    "    Finally, it shows as horizontal lines the thresholds used for defining change in Peter's algorithm\n",
    "    \"\"\" \n",
    "    # get the data, filter cloud, filter noise, calculate rolling average, drop NaN rows, calc difference\n",
    "    df = gatherAndPrepTSData(xpos, ypos, ts_bands)\n",
    "    # can't remember what this is for, I think it can be deleted now\n",
    "    yearDiff = True\n",
    "\n",
    "    # see if/when that pixel changed\n",
    "    changedate = getChangeDate(xpos, ypos)\n",
    "    changed = False\n",
    "    if isinstance(changedate, list):     #changedate only returns a list if there was change\n",
    "        changed = True\n",
    "        # if it did change, get the row numbers of the first and last scene taken during the change quarter\n",
    "        # to draw the box aronud the potential change period\n",
    "        changetimerange = getChangePeriodTimeRange(df, changedate)\n",
    "    \n",
    "    # only plot up the first 4 bands requested (this might be changed soon)\n",
    "    cols = list(df.columns)\n",
    "    colours = ['green', 'red', 'blue', 'orange', 'black']\n",
    "    axs = []\n",
    "    n_axes = min(len(cols),5)\n",
    "\n",
    "    # setup some variables for use during the plotting\n",
    "    leftline = getSceneFilteredIndex(left_scene_num, df)    \n",
    "    rightline = getSceneFilteredIndex(right_scene_num, df)    \n",
    "    albedo_thresh = 0.04\n",
    "    evi_thresh = -0.05\n",
    "    resid_evi = 0.18    \n",
    "    \n",
    "    #start plotting\n",
    "    plt.plot(range(len(df)), df[cols[0]], color=colours[0], label = cols[0])\n",
    "    ax0 = plt.gca()\n",
    "    pos1 = ax0.get_position()\n",
    "    pos2 = pos1\n",
    "#     pos2 = [pos1.x0 + (0.03 * n_axes), pos1.y0,  pos1.width / (1 + (0.1 * (n_axes - 1))), pos1.height] \n",
    "    ax0.set_position(pos2)\n",
    "    ax0.spines['right'].set_color(colours[0])\n",
    "\n",
    "    # draw the scene viewer lines\n",
    "    ax0.axvline(x = leftline[0], linestyle = leftline[1]) \n",
    "    ax0.axvline(x = rightline[0], linestyle = rightline[1])\n",
    "    \n",
    "    # draw a zero line (x axis) for the TSDiff lines\n",
    "    ax0.axhline(y = 0, color = 'black', linestyle = '-')\n",
    "     \n",
    "    # if there was change, draw the yellow rectangle    \n",
    "    if changed:\n",
    "        ax0.axvspan(changetimerange[0],changetimerange[1], color = 'gold', alpha = 0.7)\n",
    "#         yrange = define_TS_YAxisRange(df[cols[0]], yearDiff, 2)\n",
    "#         ax0.text(changetimerange[1], yrange[1] - ((yrange[1] - yrange[0]) / 10), changedate)\n",
    "        \n",
    "    # twin the x axis for creating a date axis on the top\n",
    "    ax_date = ax0.twiny()\n",
    "    # plot some random data with 100% transparency to make the axis appear\n",
    "    ax_date.plot(df.index, df[cols[0]], alpha = 0)\n",
    "    # set the axis to overlap with the original axis\n",
    "    ax_date.set_position(pos2)\n",
    "    \n",
    "    # create a title that specifies the area being displayed\n",
    "    readable_coords = 'x = ' + str(xpos[0]) + ':' + str(xpos[1]) + ', y = ' + str(ypos[0]) + ':' + str(ypos[1])\n",
    "    ax0.set_title('Time Series values for pixels ' + readable_coords, y = 0)\n",
    "\n",
    "    # for all the subsequent axes (not the first column)\n",
    "    for i in range(1, n_axes):\n",
    "        # twin the original axes\n",
    "        axn = ax0.twinx()\n",
    "        axn.set_position(pos2)\n",
    "        # set the spines and the position and the colour\n",
    "        axn.spines['right'].set_position(('axes', - (0.1 * i)))\n",
    "        axn.spines['right'].set_color(colours[i])\n",
    "        # plot the data, coloured accordingly\n",
    "        axn.plot(range(len(df)), df[cols[i]], color=colours[i], label = cols[i])\n",
    "        # add to the axs list of axes\n",
    "        axs.append(axn)\n",
    "    \n",
    "    # the original axis to the start of the list\n",
    "    axs = [ax0] + axs\n",
    "    \n",
    "    for i, ax in enumerate(axs):\n",
    "        # for each axis, calculate the appropriate yaxis range, and set the xaxis range\n",
    "        yrange = define_TS_YAxisRange(df[cols[i]], ts_bands[i]['TSDiff'], 2)\n",
    "        ax.set_ylim(yrange)\n",
    "        ax.set_xlim([0, len(df)])\n",
    "        \n",
    "        if i == 0:\n",
    "            # if its the first axis, move the yaxis label\n",
    "            ax.set_ylabel(cols[i], color=colours[i], labelpad = -10)\n",
    "            # getting specific to the use case now, must be EVIDiff as first column\n",
    "            ax.axhline(y = evi_thresh, color = colours[i], linestyle = '--')\n",
    "            # print the EVI value for the RHS displayed scene\n",
    "            after_evi = float(data[xpos[0]:xpos[1], ypos[0]:ypos[1], right_scene_num].sel(band = 'evi').mean().values)\n",
    "            ax0.text(rightline[0], yrange[1] - ((yrange[1] - yrange[0]) / 10), 'EVI = ' + str(round(after_evi, 3)))       \n",
    "        else:\n",
    "            ax.set_ylabel(cols[i], color=colours[i], labelpad = -40)\n",
    "        # more use case specificness\n",
    "        if i == 1:\n",
    "            ax.axhline(y = albedo_thresh, color = colours[i], linestyle = '--')\n",
    "        if i == 2:\n",
    "            ax.axhline(y = resid_evi, color = colours[i], linestyle = '--')\n",
    "    return axs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drawAllSubplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawAllSubplots(left_scene_num, right_scene_num, change_trans, ts_bands, xpos, ypos, BBoxWidth, BBoxHeight):\n",
    "    \"\"\"\n",
    "    This function defines what plots will be shown, and in what order. This function is called\n",
    "    by the the analyse function and also during the onclick event.\n",
    "    It returns nothing, but draws the axes on command\n",
    "    \"\"\"\n",
    "    # the xpos and ypos here come from the mouse click event, ie are a pixel coordinate.\n",
    "    # need to convert this to a list for use as a bounding box\n",
    "     \n",
    "    if BBoxWidth == 1:\n",
    "        # if only a pixel is wanted, the list will be len == 1\n",
    "        xrange = [xpos, xpos + 1]\n",
    "    else:\n",
    "        # split the witdth in half and take either side\n",
    "        # might need to confirm edge cases here...?\n",
    "        xrange = [int(xpos - BBoxWidth/2), int(xpos + BBoxWidth/2)]\n",
    "    \n",
    "    if BBoxHeight == 1:\n",
    "        yrange = [ypos, ypos + 1]\n",
    "    else:\n",
    "        yrange = [int(ypos - BBoxHeight/2), int(ypos + BBoxHeight/2)]\n",
    "    \n",
    "    # might need some changing in the future regarding formating, plot spacing etc.   \n",
    "    ax1 = plt.subplot2grid([7,4],[0,0], rowspan = 2, colspan = 2)\n",
    "    ax1.clear()\n",
    "    ax1 = drawScene(left_scene_num, change_trans, xrange, yrange)    \n",
    "\n",
    "    ax2 = plt.subplot2grid([7,4],[0,2], rowspan = 2, colspan = 2)\n",
    "    ax2.clear()\n",
    "    ax2 = drawScene(right_scene_num, change_trans, xrange, yrange)  \n",
    "\n",
    "    ax3 = plt.subplot2grid([7,4],[2,0], rowspan = 2, colspan = 4)\n",
    "    ax3.clear()\n",
    "    ax3 = drawTimeSeries(xrange, yrange, ts_bands, left_scene_num, right_scene_num)\n",
    "\n",
    "    ax4 = plt.subplot2grid([7,4],[4,0], rowspan = 2, colspan = 2)\n",
    "    ax4.clear()\n",
    "    ax4 = drawScatter(left_scene_num, ts_bands, xrange, yrange)    \n",
    "\n",
    "    ax5 = plt.subplot2grid([7,4],[4,2], rowspan = 2, colspan = 2)\n",
    "    ax5.clear()\n",
    "    ax5 = drawScatter(right_scene_num, ts_bands, xrange, yrange) \n",
    "    \n",
    "    ax6 = plt.subplot2grid([7,4],[6,0], rowspan = 1, colspan = 2)        \n",
    "    ax6.clear()\n",
    "    ax6 = drawSpectrum(xrange, yrange, left_scene_num)                       \n",
    "\n",
    "    ax7 = plt.subplot2grid([7,4],[6,2], rowspan = 1, colspan = 2)\n",
    "    ax7.clear()\n",
    "    ax7 = drawSpectrum(xrange, yrange, right_scene_num)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "global xpos\n",
    "global ypos\n",
    "xpos = 0\n",
    "ypos = 0\n",
    "  \n",
    "def analysis(left_scene_num, right_scene_num, change_trans, ts_bands, BBoxWidth = 1, BBoxHeight = 1):\n",
    "\n",
    "    def onclick(event):\n",
    "        # defining what to do on a click event\n",
    "        \n",
    "        # I don't understand why this need to be declared global again, but it breaks without these lines\n",
    "        global xpos\n",
    "        global ypos\n",
    "        # need to cast to int as result is a float, and can't index a list with a float\n",
    "        xpos = int(event.xdata)\n",
    "        ypos = int(event.ydata)\n",
    "        drawAllSubplots(left_scene_num, right_scene_num, change_trans, ts_bands, xpos, ypos, BBoxWidth, BBoxHeight)\n",
    "    \n",
    "    # control the figure size\n",
    "    fig = plt.figure(figsize=[10,15])\n",
    "    plt.subplots_adjust(hspace = 0.6)\n",
    "    \n",
    "    # draw the figure\n",
    "    drawAllSubplots(left_scene_num, right_scene_num, change_trans, ts_bands, xpos, ypos, BBoxWidth, BBoxHeight)\n",
    "    #connect the click event action to the figure\n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0398933c3651455aa1c3885a9157c443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Left Scene Number', max=671), IntSlider(value=671, description='Right Scene Number', max=671), FloatSlider(value=0.6, description='Change Mask Transparency', max=1.0), IntSlider(value=1, description='BBox Width', max=171, min=1), IntSlider(value=1, description='BBox Height', max=143, min=1), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TS_BANDS is the key datastructure for the whole setup.\n",
    "# it is a list of dicts, each dict being the details required for the timeseries data gathering and preparation\n",
    "# the first 2 items in the list will have their bands used as the x and y axis for the scatter plot\n",
    "\n",
    "# *** dict keys and their use***\n",
    "# name = the name of the dataseries on the resultant plot\n",
    "# band = the band on which the analysis is based, this is used to directly access the xarray, so it must be identical\n",
    "    # to the band in the xarray. \n",
    "# cloud_mask = Boolean as to if you want to use the cloud mask\n",
    "# smoothed = Boolean as to if you want to use the smoothing filter\n",
    "# RollingAve = Boolean as to if you want to use an annual rolling average rather than a raw/smoothed reading\n",
    "# TSDiff = Boolean as to if you want to use the difference between that reading and the one 12 months ago.\n",
    "\n",
    "ts_bands = [\n",
    "    {'name':'evi_diff', 'band':'evi', 'cloud_mask':True, 'smoothed':True, 'RollingAve':True, 'TSDiff':True},\n",
    "    {'name':'albedo_diff', 'band':'albedo', 'cloud_mask':True, 'smoothed':True, 'RollingAve':True, 'TSDiff':True},\n",
    "    {'name':'evi_raw', 'band':'evi', 'cloud_mask':True, 'smoothed':True, 'RollingAve':False, 'TSDiff':False}]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    interact(analysis,\n",
    "             left_scene_num = IntSlider(value = 1, min = 0, max = num_scenes -1,\n",
    "                                        description = \"Left Scene Number\"),\n",
    "             right_scene_num = IntSlider(value = num_scenes -1, min = 0, max = num_scenes -1,\n",
    "                                         description = \"Right Scene Number\"),\n",
    "             change_trans = FloatSlider(value = 0.6, min = 0, max = 1, description = \"Change Mask Transparency\"),\n",
    "#              ts_bands = fixed(['evi','albedo']),\n",
    "             ts_bands = fixed(ts_bands),\n",
    "            BBoxWidth = IntSlider(value = 1, min = 1, max = x, description = \"BBox Width\"),\n",
    "            BBoxHeight = IntSlider(value = 1, min = 1, max = y, description = \"BBox Height\"))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "818px",
    "left": "0px",
    "right": "1044px",
    "top": "111px",
    "width": "252px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "state": {
    "c52feb267d464c0681dc5b8825029c6a": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
