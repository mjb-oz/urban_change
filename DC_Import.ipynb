{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import From Digital Earth Australia NBAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates an interactive graph that allows the user to choose Landsat and NDVI imagery of a scene before and after a tropical cyclone. The difference of NDVI before and after the tropical cylone is then visualised. Finally, the notebook is used to import cyclone windfield data and examine the relationship between wind speed and NDVI change.\n",
    "\n",
    "Cells titled \"user requirement\" indicate where users are required to edit code, the remaining code should be run normally. \n",
    "\n",
    "Code written in Janurary 2018 by Erin Telfer with support from Claire Krause. The notebook was completed as a graduate program project at Geoscience Australia. If you have comment or if you find an error, please contact erin.telfer@ga.gov.au. Alternatively, please contact Claire.Krause@ga.gov.au."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Import libraries \n",
    "\n",
    "%pylab notebook\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import date, timedelta\n",
    "import gdal\n",
    "from gdal import *\n",
    "\n",
    "import datacube\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n",
    "from datacube.storage.masking import mask_to_dict\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import rasterio\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "dc = datacube.Datacube(app='dc-show changes in annual mean NDVI values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User requirement: specify directory locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##User input: enter the directory location of input data. Ensure \"/\" are used, not \"\\\"\n",
    "input_folder = '/g/data/u46/users/mb4539/dc_test/'\n",
    "\n",
    "###User input: enter the directory location of output data. Please enter again if the same as input_folder. Ensure \"/\" are used, not \"\\\"\n",
    "output_folder = '/g/data/u46/users/mb4539/dc_test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User requirement: specifiy location of interest and details about cyclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##User input: enter area of interest\n",
    "\n",
    "# # #Boogan\n",
    "# lat_min = -17. #down\n",
    "# lat_max = -17.856 #up\n",
    "# lon_min = 146.091 #left\n",
    "# lon_max = 146.109 #right\n",
    "\n",
    "# #Mission Beach Larry\n",
    "# lat_min = -17.866 #down\n",
    "# lat_max = -17.856 #up\n",
    "# lon_min = 146.091 #left\n",
    "# lon_max = 146.109 #right\n",
    "\n",
    "\n",
    "#'Mt Dryander QLD' Debbie\n",
    "lat_min = -20.267 #down\n",
    "lat_max = -20.216 #up\n",
    "lon_min = 148.534 #left\n",
    "lon_max = 148.592 #right\n",
    "\n",
    "#High Mt QLD\n",
    "# lat_min = -20.375 #down\n",
    "# lat_max = -20.340 #up\n",
    "# lon_min = 148.757 #left\n",
    "# lon_max = 148.806 #right\n",
    "\n",
    "# lat_min = -20.385 #down\n",
    "# lat_max = -20.326 #up\n",
    "# lon_min = 148.916 #left\n",
    "# lon_max = 148.984 #right\n",
    "\n",
    "##User input: enter the name of vegetation of interest, e.g. \"forest\" or \"banana crop\"\n",
    "vegetation_type = 'forest'\n",
    "\n",
    "##User input: enter the name of the area/region/place/location of interest, e.g. \"Hamilton Island\"\n",
    "location_name = 'Mt Dryander QLD'\n",
    "\n",
    "###User input: enter start and end date of cyclone\n",
    "start_of_event= '2017-03-23'\n",
    "end_of_event= '2017-04-07'\n",
    "\n",
    "###User input: enter the name of cyclone\n",
    "cyclone_name =  'Debbie'\n",
    "\n",
    "###User input: set cloud threshold. This value defines the amount of lansdcape/cloud allowed in each scene. Scenes will not be retrieved that have less than the cloud threshold worth of image.\n",
    "#The default value is \"0.90\" or >90% image and <10% cloud cover\n",
    "cloud_free_threshold = 0.80 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datacube query is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': ('2000-01-01', '2017-12-31'), 'x': (148.534, 148.592), 'y': (-20.216, -20.267), 'crs': 'EPSG:4326'}\n"
     ]
    }
   ],
   "source": [
    "#Temporal range, wavelengths/band and sensors of interest are defined\n",
    "\n",
    "#temporal range is defined\n",
    "start_of_epoch = '2000-01-01'\n",
    "end_of_epoch =  '2017-12-31'\n",
    "\n",
    "#wavelengths/bands of interest are defined\n",
    "bands_of_interest = [#'blue',\n",
    "                     'green',\n",
    "                     'red', \n",
    "                     'nir',\n",
    "                     'swir1', \n",
    "                     #'swir2'\n",
    "                     ]\n",
    "\n",
    "#Landsat sensors of interest are defined\n",
    "sensors = ['ls8',\n",
    "       'ls7',\n",
    "      'ls5'] \n",
    "\n",
    "#query is created\n",
    "query = {'time': (start_of_epoch, end_of_epoch),}\n",
    "query['x'] = (lon_min, lon_max)\n",
    "query['y'] = (lat_max, lat_min)\n",
    "query['crs'] = 'EPSG:4326'\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat variables\n",
    "\n",
    "start_of_event=datetime.datetime.strptime(start_of_event,'%Y-%m-%d') #Convert to datetime\n",
    "end_of_event=datetime.datetime.strptime(end_of_event,'%Y-%m-%d') #Convert to datetime\n",
    "location_name=location_name.replace(\" \",\"_\") #replace spaces with underscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data is extracted from Open Datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted data is first filtered using the criteria in \"mask_components\". \n",
    "The cloudiness of the scenes is then tested, and any scenes that do not meet the given \"cloud_free_threshold\" are discarded.\n",
    "Additionally, any pixel that is located within the ocean/sea will be converted to \"nan\" values with the 'land_sea' command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create cloud mask. This will define which pixel quality (PQ) artefacts are removed from the results. It should be noted the \"land_sea\" code will remove all ocean/sea pixels.\n",
    "\n",
    "mask_components = {'cloud_acca':'no_cloud',\n",
    "'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "'cloud_fmask' :'no_cloud',\n",
    "'blue_saturated' : False,\n",
    "'green_saturated' : False,\n",
    "'red_saturated' : False,\n",
    "'nir_saturated' : False,\n",
    "'swir1_saturated' : False,\n",
    "'swir2_saturated' : False,\n",
    "'contiguous':True,\n",
    "'land_sea': 'land'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ls8\n",
      "loaded ls7\n",
      "loaded ls5\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "#Data for each Landsat sensor is retrieved\n",
    "\n",
    "sensor_clean = {}\n",
    "\n",
    "for sensor in sensors:\n",
    "    #Load the NBAR and corresponding PQ\n",
    "    sensor_nbar = dc.load(product= sensor+'_nbar_albers', group_by='solar_day', \n",
    "                          measurements = bands_of_interest,  **query)\n",
    "    sensor_pq = dc.load(product= sensor+'_pq_albers', group_by='solar_day', \n",
    "                        fuse_func=ga_pq_fuser, **query)\n",
    "    \n",
    "    #Retrieve the projection information before masking/sorting\n",
    "    crs = sensor_nbar.crs\n",
    "    crswkt = sensor_nbar.crs.wkt\n",
    "    affine = sensor_nbar.affine\n",
    "    \n",
    "    #Ensure there's PQ to go with the NBAR\n",
    "    sensor_nbar = sensor_nbar.sel(time = sensor_pq.time)\n",
    "    \n",
    "    #Apply the PQ masks to the NBAR\n",
    "    quality_mask = masking.make_mask(sensor_pq, **mask_components)\n",
    "    good_data = quality_mask.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "    sensor_nbar2 = sensor_nbar.where(good_data)\n",
    "    \n",
    "    #Calculate the percentage cloud free for each scene\n",
    "    cloud_free = masking.make_mask(sensor_pq, cloud_acca='no_cloud', cloud_fmask='no_cloud', \n",
    "                                   contiguous=True).pixelquality\n",
    "    mostly_cloud_free = cloud_free.mean(dim=('x','y')) >= cloud_free_threshold\n",
    "        \n",
    "    #Discard data that does not meet the cloud_free_threshold\n",
    "    mostly_good = sensor_nbar2.where(mostly_cloud_free).dropna(dim='time', how='all')\n",
    "    \n",
    "    mostly_good['product'] = ('time', numpy.repeat(sensor, mostly_good.time.size))    \n",
    "    sensor_clean[sensor] = mostly_good\n",
    "\n",
    "    print('loaded %s' % sensor) \n",
    "    \n",
    "\n",
    "print ('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 27, x: 269, y: 257)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 2013-06-27T00:06:47 2013-08-14T00:06:51 ...\n",
       "  * y        (y) float64 -2.279e+06 -2.279e+06 -2.279e+06 -2.279e+06 ...\n",
       "  * x        (x) float64 1.714e+06 1.714e+06 1.714e+06 1.714e+06 1.714e+06 ...\n",
       "Data variables:\n",
       "    green    (time, y, x) float64 287.0 276.0 302.0 307.0 325.0 288.0 261.0 ...\n",
       "    red      (time, y, x) float64 192.0 176.0 202.0 202.0 215.0 190.0 175.0 ...\n",
       "    nir      (time, y, x) float64 2.434e+03 2.429e+03 2.49e+03 2.536e+03 ...\n",
       "    swir1    (time, y, x) float64 927.0 936.0 954.0 1.067e+03 1.13e+03 993.0 ...\n",
       "    product  (time) <U3 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' ...\n",
       "Attributes:\n",
       "    crs:      EPSG:3577"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the output\n",
    "\n",
    "sensor_clean['ls8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Data from different sensors are joined together and sorted so that observations are sorted by time rather than sensor\n",
    "nbar_clean = xr.concat(sensor_clean.values(), 'time')\n",
    "nbar_clean = nbar_clean.sortby('time')\n",
    "nbar_clean.attrs['crs'] = crs\n",
    "nbar_clean.attrs['affin|e'] = affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 145, x: 269, y: 257)\n",
       "Coordinates:\n",
       "  * y        (y) float64 -2.279e+06 -2.279e+06 -2.279e+06 -2.279e+06 ...\n",
       "  * x        (x) float64 1.714e+06 1.714e+06 1.714e+06 1.714e+06 1.714e+06 ...\n",
       "  * time     (time) datetime64[ns] 2000-06-30T23:56:29.500000 ...\n",
       "Data variables:\n",
       "    green    (time, y, x) float64 205.0 206.0 206.0 267.0 236.0 236.0 206.0 ...\n",
       "    red      (time, y, x) float64 135.0 189.0 162.0 162.0 135.0 189.0 162.0 ...\n",
       "    nir      (time, y, x) float64 2.473e+03 2.278e+03 2.473e+03 2.667e+03 ...\n",
       "    swir1    (time, y, x) float64 839.0 803.0 839.0 944.0 979.0 909.0 698.0 ...\n",
       "    product  (time) <U3 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' ...\n",
       "Attributes:\n",
       "    crs:      EPSG:3577\n",
       "    affin|e:  | 25.00, 0.00, 1713675.00|\\n| 0.00,-25.00,-2279200.00|\\n| 0.00,..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that the concatenation worked\n",
    "\n",
    "nbar_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
